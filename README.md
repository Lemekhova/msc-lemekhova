# Исследование методов эффективного применения адаптеров (LoRA)  для дообучения моделей в условиях ограниченных вычислительных ресурсов
1. Введение

1.1. Актуальность применения языковых моделей

Рост параметров LLM

Ограниченност вычислительных ресурсов

Необходимость воспроизводимости результатов исследований

Практическое применение

1.2. Цель и задачи исследования

Цель — исследовать эффективность применения LoRA-адаптеров для дообучения языковых моделей и разработать воспроизводимый пайплайн обучения и инференса.

Задачи:

проанализировать методы PEFT для LLM

реализовать baseline с полным fine-tuning

реализовать дообучение с использованием LoRA

сравнить подходы по качеству и ресурсам

сформировать воспроизводимую итоговую модель в контейнере Docker и разработать сервис

1.3. Объект и предмет исследования

1.4. Научная новизна и практическая значимость

1.5. Структура работы

2. Обзор литературы и теоретические основы

2.1. Архитектура трансформеров в языковых моделях

2.2. Подходы к адаптации языковых моделей

2.3  Существующие методы

2.4. Теоретические основы метода LoRA

2.5  Выводы

3. Анализ существующих решений и инструментов

3.1. Open-source библиотеки для дообучения LLM

3.2. Сравнение подходов к дообучению

4. Подготовка и анализ данных
   
4.1. Постановка NLP-задачи (одна или несколько задач, например, Классификация текстов)
     
4.2. Описание и источники данных

4.3. Сбор, очистка и обработка данных

4.4. Формирование обучающих выборок

4.5. EDA

5. Построение baseline-модели
   
5.1. Выбор базовой языковой модели

5.2. Полное дообучение модели (Full Fine-Tuning) - Пункт под вопросом ?
     
     Архитектура
     
     Настройки обучения
     
     Ограничения по ресурсам
     
5.3. Метрики качества

5.4. Результаты baseline

6. Дообучение языковой модели с использованием LoRA
   
6.1. Интеграция LoRA в архитектуру модели

6.2. Настройка гиперпараметров LoRA

6.3. Экспериментальная схема обучения

6.4. Эксперименты

7. Анализ и визуализация результатов (дашборд?)

7.1. Сравнение LoRA и Full Fine-Tuning

7.2. Дашборд экспериментов ?

7.3. Анализ «качество – ресурсы»

8. Формирование итоговой модели и разработка сервиса

8.1. Выбор сценария практического применения

8.2. Архитектура сервиса языковой модели

8.3. Интеграция LoRA-адаптеров в пайплайн

8.4. Реализация сервиса (API / бот / web-приложение ?)

8.5. Контейнеризация сервиса (Docker)

8.6. Инструкции по воспроизведению и запуску

README

Пример запуска

Ограничения по ресурсам

9. Экспериментальная проверка воспроизводимости
    
9.1. Повторный запуск в Docker

9.2. Сравнение результатов

9.3. Анализ стабильности результатов

10. Заключение
    
Основные результаты

Выводы по применению LoRA

Практическая применимость решения

11. Список литературы
    
12. Приложения
    
Dockerfile

Конфигурации обучения

Скрипты

Ссылки на репозиторий
